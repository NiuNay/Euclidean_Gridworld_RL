WALL_CHARACTER = "#"
OPEN_CHARACTER = " "
START_CHARACTER = "S"
REWARD_CHARACTER = "R"
H_BLOCK_CHARACTER = "H"
K_BLOCK_CHARACTER = "K"
MAP_PATH = "map_path"
MAP_PATHS = "map_paths"
REPRESENTATION = "representation"
PO_PIXEL = "po_pixel"
REWARD_POSITIONS = "reward_positions"
START_POSITION = "start_position"
REWARD_ATTRIBUTES = "reward_attributes"
AVAILABILITY = "availability"
STATISTICS = "statistics"
GAUSSIAN = "gaussian"
MEAN = "mean"
VARIANCE = "variance"
INFINITE = "infinite"
AGENT_POSITION = "agent_position"
STATIONARY = "stationary"
STATE = "state"
BEHAVIOUR = "behaviour"
LEARNING_RATE = "learning_rate"
DISCOUNT_FACTOR = "discount_factor"
INITIALISATION = "initialisation"
INITIALISATION_TYPE = "initialisation_type"
TYPE = "type"
TARGET = "target"
RANDOM_UNIFORM = "random_uniform"
RANDOM_NORMAL = "random_normal"
MEAN = "mean"
VARIANCE = "variance"
GREEDY = "greedy"
EPSILON_GREEDY = "epsilon_greedy"
TRAIN_EPISODE_REWARD = "train_episode_reward"
TRAIN_EPISODE_LENGTH = "train_episode_length"
LOWER_BOUND = "lower_bound"
UPPER_BOUND = "upper_bound"
MODEL = "model"
ENVIRONMENT = "environment"
EPSILON = "epsilon"
RESULTS = "results"
Q_LEARNING = "q_learning"
ESCAPE_ENV = "escape_env"
PIXEL = "pixel"
ZEROS = "zeros"
ONES = "ones"
GAUSSIAN_MEAN = "gaussian_mean"
GAUSSIAN_VARIANCE = "gaussian_variance"
SINGLE = "single"
PARAMETERS = "parameters"
MAP_ASCII_PATH = "map_ascii_path"
NUM_EPISODES = "num_episodes"
NUM_STEPS = "num_steps"
EPISODE_TIMEOUT = "episode_timeout"
VISUALISATION_FREQUENCY = "visualisation_frequency"
TEST_FREQUENCY = "test_frequency"
ROLLOUT_FREQUENCY = "rollout_frequency"
VISUALISATIONS = "visualisations"
ROLLOUTS = "rollouts"
INDIVIDUAL_TRAIN_RUN = "individual_train_run"
INDIVIDUAL_TEST_RUN = "individual_test_run"
TRAIN = "train"
PARALLEL = "parallel"
SERIAL = "serial"
CLUSTER = "cluster"
SEED = "seed"
STEP = "step"
INTERPOLATION = "interpolation"
VALUES_PDF = "values.pdf"
VISITATION_COUNTS_PDF = "visitation_counts.pdf"
SINGLE_PARALLEL = "single_parallel"
SINGLE_SERIAL = "single_serial"
SINGLE_CLUSTER = "single_cluster"
TRAIN_MAP_PATH = "train_map_path"
TEST_MAP_PATHS = "test_map_paths"
LEARNING = "learning"
ENV_NAME = "env_name"
TRAIN_ENVIRONMENT = "train_environment"
TEST_ENVIRONMENTS = "test_environments"
TEST = "test"
TRAINING = "training"
TRAIN_STATISTICS = "train_statistics"
TEST_STATISTICS = "test_statistics"
TRAINING = "training"
TEST_EPISODE_REWARD = "test_episode_reward"
TEST_EPISODE_LENGTH = "test_episode_length"
IMPUTATION_METHOD = "imputation_method"
NEAR_NEIGHBOURS = "near_neighbours"
RANDOM = "random"
TRAIN_REWARD = "train_reward"
CHECKPOINT_FREQUENCY = "checkpoint_frequency"
GREEDY_SAMPLE = "greedy_sample"
SUCCESSOR_REP = "successor_rep"
FINAL_REWARD_RUN = "final_reward_run"
AGENT_POSITION_REWARD = "agent_position_reward"
WALL_STATE_SPACE = "wall_state_space"
K_BLOCK_STATE_SPACE = "k_block_state_space"
H_BLOCK_STATE_SPACE = "h_block_state_space"
REWARDS_RECEIVED_STATE_SPACE = "rewards_received_state_space"
STATE_SPACE = "state_space"
POSITIONAL_STATE_SPACE = "positional_state_space"
LOGGING = "logging"
ENV_SKELETON = "env_skeleton"
TRAJECTORIES = "trajectories"
SR_REWARD_FUNCTION_PDF = "sr_reward_function.pdf"
SR_REWARD_POS_PLACE_FIELD_PDF = "sr_reward_pos_place_field.pdf"
PLAN_STEPS_PER_UPDATE = "plan_steps_per_update"
DYNA = "dyna"
A_STAR = "a_star"
FOUR_DELTAS = [[0, 1], [0, -1], [1, 0], [-1, 0]]
ESCAPE_ENV_DIAGONAL = "escape_env_diagonal"
